# ğŸ” RAG - Retrieval Augmented Generation

## ğŸ“– Sobre este MÃ³dulo

**RAG** Ã© uma das tÃ©cnicas mais importantes da IA Generativa moderna! Ela combina **busca de informaÃ§Ãµes** (retrieval) com **geraÃ§Ã£o de texto** (generation) para criar sistemas que respondem perguntas baseadas em documentos especÃ­ficos.

Este Ã© o **æ ¸å¿ƒ (coraÃ§Ã£o)** do projeto final - o Assistente TÃ©cnico que entenderÃ¡ todo o seu cÃ³digo!

---

## ğŸ¯ Objetivos de Aprendizado

Ao completar este mÃ³dulo, vocÃª serÃ¡ capaz de:

- âœ… Entender **embeddings** e busca vetorial
- âœ… Implementar diferentes estratÃ©gias de **chunking**
- âœ… Criar um **pipeline RAG completo**
- âœ… Usar **FAISS** para busca eficiente
- âœ… Implementar **reranking** e busca hÃ­brida
- âœ… Criar RAG especializado para **cÃ³digo Python**
- âœ… Avaliar e otimizar sistemas RAG

---

## ğŸ“š ConteÃºdo

### ğŸ““ Notebooks

1. **embeddings_vetores.ipynb** ğŸ”¢
   - O que sÃ£o embeddings
   - Modelos de embedding (OpenAI, Sentence-Transformers)
   - Similaridade de cosseno
   - FAISS: busca vetorial eficiente
   - Diferentes tipos de Ã­ndices
   - VisualizaÃ§Ã£o com PCA
   - ComparaÃ§Ã£o entre modelos

2. **02_chunking_estrategias.ipynb** âœ‚ï¸
   - Por que fazer chunking?
   - EstratÃ©gias: tamanho fixo, recursivo, semÃ¢ntico
   - Overlap entre chunks
   - Chunking para cÃ³digo (por funÃ§Ã£o, classe)
   - Metadata e filtragem
   - ComparaÃ§Ã£o de estratÃ©gias

3. **03_rag_basico.ipynb** ğŸ—ï¸ (æ ¸å¿ƒ!)
   - Pipeline RAG completo
   - Document loaders (PDF, TXT, CSV, cÃ³digo)
   - Text splitters
   - Vector stores (FAISS, ChromaDB)
   - Retrieval strategies
   - Chain de Q&A com LangChain
   - Prompts customizados
   - AvaliaÃ§Ã£o de RAG

4. **04_rag_avancado.ipynb** ğŸš€
   - Reranking com Cohere
   - Hybrid search (keyword + semantic)
   - Query rewriting/expansion
   - Multi-query retrieval
   - Contexto multi-hop
   - Self-query retriever
   - CitaÃ§Ãµes precisas

5. **05_rag_codigo_especializado.ipynb** ğŸ’»
   - Parse de AST (Abstract Syntax Tree)
   - ExtraÃ§Ã£o de funÃ§Ãµes e classes
   - Linking entre arquivos
   - AnÃ¡lise de dependÃªncias
   - IndexaÃ§Ã£o de notebooks (.ipynb)
   - Busca por tipo (funÃ§Ã£o, classe, variÃ¡vel)
   - Metadata rica para cÃ³digo

---

## ğŸ”§ Tecnologias Utilizadas

### Core RAG
- `langchain` - Framework RAG completo
- `langchain-openai` - IntegraÃ§Ã£o OpenAI
- `openai` - Embeddings e LLM

### Vector Stores
- `faiss-cpu` - Busca vetorial eficiente
- `chromadb` - Vector database alternativa
- `pinecone-client` - Cloud vector database (opcional)

### Embeddings
- `sentence-transformers` - Modelos open source
- `openai` - text-embedding-3-small/large

### Utilities
- `pypdf` - Processar PDFs
- `python-docx` - Processar Word
- `nbformat` - Processar notebooks

---

## ğŸš€ Como Usar

```bash
# 1. Instalar dependÃªncias
pip install langchain langchain-openai faiss-cpu sentence-transformers

# 2. Configurar API Key
echo "OPENAI_API_KEY=sk-..." > .env

# 3. ComeÃ§ar pelos fundamentos
jupyter notebook embeddings_vetores.ipynb

# 4. Pipeline completo
jupyter notebook 03_rag_basico.ipynb
```

---

## ğŸ’° Custos Estimados

| Atividade | Custo |
|-----------|-------|
| Criar embeddings (1000 docs) | $0.10 |
| Queries de teste (100x) | $0.50 |
| Desenvolvimento completo | $2-3 |
| **Total mÃ³dulo** | **~$3-4** |

**Dica:** Use `text-embedding-3-small` (mais barato e suficiente)

---

## ğŸ“Š PrÃ©-requisitos

- âœ… **MÃ³dulo 02:** Modelos PrÃ©-Treinados
- âœ… **OpenAI API Key** (para embeddings + LLM)
- âœ… **8GB RAM** (para FAISS com datasets mÃ©dios)
- ğŸ“š **Documentos para indexar** (PDFs, cÃ³digo, etc)

---

## ğŸ“ Conceitos-Chave

### ğŸ“Š Embeddings
RepresentaÃ§Ã£o vetorial de texto que captura significado semÃ¢ntico.
```python
"cachorro" = [0.2, 0.8, -0.3, ...]
"cÃ£o" = [0.21, 0.79, -0.31, ...]  # Vetores similares!
```

### ğŸ” Vector Search
Busca por similaridade em espaÃ§o vetorial, nÃ£o por palavras-chave.

### âœ‚ï¸ Chunking
DivisÃ£o de documentos em pedaÃ§os menores para melhor recuperaÃ§Ã£o.

### ğŸ¯ RAG Pipeline
```
Query â†’ Embedding â†’ Busca â†’ Top-K Docs â†’ Prompt + Docs â†’ LLM â†’ Answer
```

### ğŸ” Reranking
Segunda etapa de busca que reordena resultados para maior precisÃ£o.

---

## ğŸ’¡ Arquitetura RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              1. INDEXAÃ‡ÃƒO (offline)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Documentos â†’ Chunking â†’ Embeddings â†’ Vector DB â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. QUERY (runtime)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query â†’ Embedding â†’ Search â†’ Top-K â†’ Context   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              3. GENERATION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Context + Query â†’ LLM â†’ Answer com citaÃ§Ãµes    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Casos de Uso

### 1. Chatbot Corporativo
- Responde baseado em docs internos
- PDFs, Wikis, Confluence, etc.

### 2. Assistente de CÃ³digo
- Busca em repositÃ³rios Git
- Explica implementaÃ§Ãµes
- **â† Este Ã© nosso projeto!**

### 3. Sistema de FAQ
- Busca semÃ¢ntica em perguntas frequentes
- Melhor que busca por palavra-chave

### 4. AnÃ¡lise de Documentos
- ExtraÃ§Ã£o de informaÃ§Ãµes
- SumarizaÃ§Ã£o de mÃºltiplos docs

---

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

### Retrieval
- **Precision@K:** Quantos dos top-K sÃ£o relevantes?
- **Recall@K:** Quantos relevantes estÃ£o no top-K?
- **MRR:** Mean Reciprocal Rank

### Generation
- **Faithfulness:** Resposta fiel aos documentos?
- **Relevance:** Resposta relevante Ã  pergunta?
- **Coherence:** Resposta coerente?

---

## ğŸ”— PrÃ³ximos Passos

ApÃ³s dominar RAG, vocÃª pode:

- ğŸ¤– **MÃ³dulo 05:** Criar agentes que usam RAG como ferramenta
- ğŸ¯ **MÃ³dulo 06:** Projeto Final - Assistente TÃ©cnico
- ğŸ”§ **Integrar:** RAG em aplicaÃ§Ãµes web (Flask, Streamlit)

---

## ğŸ“š Recursos Adicionais

### Papers Fundamentais
- [RAG Paper (Original)](https://arxiv.org/abs/2005.11401)
- [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906)
- [ColBERT: Efficient Passage Search](https://arxiv.org/abs/2004.12832)

### Tutoriais
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [RAG from Scratch](https://github.com/langchain-ai/rag-from-scratch)
- [Building Production RAG](https://www.anthropic.com/index/building-effective-agents)

### Ferramentas
- [FAISS Documentation](https://faiss.ai/)
- [ChromaDB](https://www.trychroma.com/)
- [Weaviate](https://weaviate.io/)

---

## ğŸ¯ ExercÃ­cios PrÃ¡ticos

### ExercÃ­cio 1: RAG para seus projetos
Indexar descriÃ§Ãµes de seus projetos anteriores (EAI_01 a EAI_06) e criar sistema de busca.

### ExercÃ­cio 2: Comparar estratÃ©gias
Testar 3 estratÃ©gias de chunking diferentes e comparar qualidade das respostas.

### ExercÃ­cio 3: Multi-Ã­ndice
Criar Ã­ndices separados para ML, DL e NLP. Implementar roteamento inteligente.

### ExercÃ­cio 4: AvaliaÃ§Ã£o
Criar dataset de 20 perguntas e respostas esperadas. Medir precisÃ£o do RAG.

---

## ğŸ’¡ Dicas Importantes

### Para Melhor Qualidade
```python
# 1. Chunk size adequado
chunk_size=1000  # NÃ£o muito pequeno, nÃ£o muito grande

# 2. Overlap suficiente
chunk_overlap=200  # Evita perder contexto

# 3. Top-K apropriado
k=5  # Nem muito pouco, nem muito

# 4. Reranking
# Use quando precisar de mÃ¡xima precisÃ£o
```

### Para Economizar
```python
# 1. Use embedding local
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

# 2. Cache embeddings
# Salve o vectorstore para nÃ£o recriar

# 3. Use GPT-3.5 para geraÃ§Ã£o
model="gpt-3.5-turbo"
```

---

## ğŸ“ˆ Status

â³ **PrÃ³ximo**

### Roadmap
- [ ] Notebook 1: Embeddings e Vetores
- [ ] Notebook 2: Chunking Strategies
- [ ] Notebook 3: RAG BÃ¡sico
- [ ] Notebook 4: RAG AvanÃ§ado
- [ ] Notebook 5: RAG para CÃ³digo

---

## ğŸ‘¨â€ğŸ’» Autor

**Carlos H. B. Marques**
- GitHub: [@RickBamberg](https://github.com/RickBamberg)
- LinkedIn: [Carlos Henrique Bamberg Marques](https://www.linkedin.com/in/carlos-henrique-bamberg-marques/)
- Email: rick.bamberg@gmail.com

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

â¬…ï¸ [Voltar: Modelos PrÃ©-Treinados](../02_Modelos_PreTreinados/README.md) | â¡ï¸ [PrÃ³ximo: Fine-Tuning](../04_Fine_Tuning/README.md)
