# ğŸ¤– Modelos PrÃ©-Treinados

## ğŸ“– Sobre este MÃ³dulo

Neste mÃ³dulo vocÃª aprenderÃ¡ a **usar modelos de linguagem jÃ¡ treinados** atravÃ©s de APIs comerciais (OpenAI, Anthropic) e locais (Ollama). Este Ã© o mÃ³dulo mais prÃ¡tico para comeÃ§ar a construir aplicaÃ§Ãµes reais com IA Generativa.

---

## ğŸ¯ Objetivos de Aprendizado

Ao completar este mÃ³dulo, vocÃª serÃ¡ capaz de:

- âœ… Fazer chamadas para **APIs de LLMs** (OpenAI GPT, Claude)
- âœ… Dominar tÃ©cnicas de **Prompt Engineering**
- âœ… Usar **Function Calling** para integrar LLMs com ferramentas
- âœ… Rodar **modelos locais** com Ollama (grÃ¡tis e privado)
- âœ… Comparar diferentes modelos e escolher o melhor para cada caso
- âœ… Gerenciar custos e otimizar uso de APIs

---

## ğŸ“š ConteÃºdo

### ğŸ““ Notebooks

1. **02_uso_apis_llm.ipynb** ğŸ”¥
   - Setup de APIs (OpenAI, Anthropic)
   - ParÃ¢metros fundamentais (temperature, max_tokens, top_p)
   - Streaming de respostas
   - Conversas com histÃ³rico (chat)
   - ComparaÃ§Ã£o: GPT-4 vs GPT-3.5 vs Claude
   - GestÃ£o de custos e otimizaÃ§Ã£o

2. **prompt_engineering.ipynb** ğŸ¨
   - Zero-shot prompting
   - Few-shot learning (1-shot, 3-shot, 5-shot)
   - Chain-of-Thought (CoT) reasoning
   - ReAct pattern (Reasoning + Acting)
   - System prompts efetivos
   - Self-consistency
   - Tree of Thoughts
   - Prompt templates reutilizÃ¡veis

3. **03_function_calling.ipynb** ğŸ”§
   - Function calling com OpenAI
   - Structured outputs (JSON mode)
   - Definir schemas de funÃ§Ãµes
   - MÃºltiplas ferramentas em sequÃªncia
   - Casos de uso prÃ¡ticos
   - SimulaÃ§Ã£o no Ollama

4. **04_modelos_locais.ipynb** ğŸ’»
   - Instalar e configurar Ollama
   - Rodar Llama 3 localmente
   - Comparar com APIs comerciais
   - QuantizaÃ§Ã£o de modelos
   - Trade-offs: custo vs qualidade vs velocidade
   - Quando usar local vs API

---

## ğŸ”§ Tecnologias Utilizadas

### APIs Comerciais
- `openai` - OpenAI GPT-3.5/GPT-4
- `anthropic` - Claude (opcional)

### Modelos Locais
- `ollama` - Framework para rodar LLMs localmente
- `llama3` - Meta's Llama 3 (open source)

### UtilitÃ¡rios
- `python-dotenv` - Gerenciar API keys
- `requests` - HTTP requests
- `langchain` - Framework para LLMs

---

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Com APIs Comerciais

```bash
# 1. Instalar dependÃªncias
pip install openai anthropic python-dotenv langchain

# 2. Criar arquivo .env
echo "OPENAI_API_KEY=sk-..." > .env
echo "ANTHROPIC_API_KEY=sk-ant-..." >> .env

# 3. Abrir notebooks
jupyter notebook 02_uso_apis_llm.ipynb
```

### OpÃ§Ã£o 2: Com Ollama (GrÃ¡tis)

```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. Baixar Llama 3
ollama pull llama3

# 3. Verificar instalaÃ§Ã£o
ollama run llama3 "Hello!"

# 4. Abrir notebooks
jupyter notebook 04_modelos_locais.ipynb
```

---

## ğŸ’° Custos Estimados

### APIs Comerciais

| Modelo | Custo/1k tokens | Uso neste mÃ³dulo |
|--------|----------------|------------------|
| GPT-3.5-turbo | $0.0015 | ~$1-2 |
| GPT-4 | $0.03 | ~$3-5 |
| Claude Sonnet | $0.003 | ~$1-2 |

**Total estimado:** $2-5 (com $5 iniciais, sobra crÃ©dito!)

### Ollama
- **Custo:** $0 (100% gratuito)
- **Hardware:** 8GB RAM mÃ­nimo
- **Modelos:** Llama 3, Mistral, CodeLlama, etc.

---

## ğŸ“Š PrÃ©-requisitos

- âœ… **MÃ³dulo 01:** Fundamentos de LLM (recomendado)
- âœ… **Python 3.11+**
- âœ… **API Key da OpenAI** (ou usar Ollama gratuitamente)
- âš ï¸ **8GB RAM** (para rodar Ollama)

---

## ğŸ“ Conceitos-Chave

### ğŸ¨ Prompt Engineering
Arte de criar instruÃ§Ãµes efetivas para LLMs obterem os melhores resultados.

### ğŸ”§ Function Calling
Permite que LLMs chamem funÃ§Ãµes externas e retornem dados estruturados (JSON).

### ğŸ’» Modelos Locais
Rodar LLMs no seu prÃ³prio computador, sem APIs, sem custo, com privacidade total.

### ğŸŒ¡ï¸ Temperature
Controla a criatividade do modelo:
- `0.0` = DeterminÃ­stico (mesma resposta sempre)
- `1.0` = Criativo (respostas variadas)
- `2.0` = Muito criativo (pode ser incoerente)

---

## ğŸ’¡ Dicas Importantes

### Para Economizar
```python
# Use GPT-3.5 para testes
model="gpt-3.5-turbo"  # 20x mais barato que GPT-4

# Limite tokens
max_tokens=500

# Temperature baixa evita retries
temperature=0
```

### Para Melhor Qualidade
```python
# Use GPT-4 para produÃ§Ã£o
model="gpt-4"

# Mais tokens para respostas completas
max_tokens=2000

# Temperature moderada
temperature=0.7
```

---

## ğŸ”— PrÃ³ximos Passos

ApÃ³s dominar modelos prÃ©-treinados, vocÃª estarÃ¡ pronto para:

- ğŸ” **MÃ³dulo 03:** Implementar RAG (busca + geraÃ§Ã£o)
- ğŸ¤– **MÃ³dulo 05:** Criar agentes autÃ´nomos
- ğŸ¯ **MÃ³dulo 06:** Projeto final (Assistente TÃ©cnico)

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Oficial
- [OpenAI API Docs](https://platform.openai.com/docs/)
- [Anthropic API Docs](https://docs.anthropic.com/)
- [Ollama Documentation](https://ollama.com/)

### Tutoriais e Cursos
- [OpenAI Cookbook](https://cookbook.openai.com/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LangChain Documentation](https://python.langchain.com/docs/)

### Papers Importantes
- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)
- [ReAct: Reasoning and Acting](https://arxiv.org/abs/2210.03629)

---

## ğŸ¯ ExercÃ­cios PrÃ¡ticos

Cada notebook inclui exercÃ­cios prÃ¡ticos:

1. **APIs:** Criar analisador de cÃ³digo automÃ¡tico
2. **Prompts:** Gerar testes unitÃ¡rios com few-shot
3. **Functions:** Integrar com busca em seus projetos
4. **Local:** Comparar Ollama vs OpenAI

---

## ğŸ“ˆ Status

ğŸš§ **Em Andamento**

### Progresso
- [x] Notebook 1: Uso de APIs âœ…
- [x] Notebook 2: Prompt Engineering âœ…
- [x] Notebook 3: Function Calling âœ…
- [ ] Notebook 4: Modelos Locais â³

---

## ğŸ‘¨â€ğŸ’» Autor

**Carlos H. B. Marques**
- GitHub: [@RickBamberg](https://github.com/RickBamberg)
- LinkedIn: [Carlos Henrique Bamberg Marques](https://www.linkedin.com/in/carlos-henrique-bamberg-marques/)
- Email: rick.bamberg@gmail.com

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

â¬…ï¸ [Voltar: Fundamentos LLM](../01_Fundamentos_LLM/README.md) | â¡ï¸ [PrÃ³ximo: RAG](../03_RAG/README.md)
