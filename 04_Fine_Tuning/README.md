# ğŸ¯ Fine-Tuning de Modelos de Linguagem

## ğŸ“– Sobre este MÃ³dulo

**Fine-Tuning** Ã© o processo de adaptar um modelo prÃ©-treinado para tarefas especÃ­ficas usando seus prÃ³prios dados. Embora RAG seja suficiente para a maioria dos casos, fine-tuning Ã© ideal quando vocÃª precisa que o modelo aprenda padrÃµes especÃ­ficos do seu domÃ­nio.

âš ï¸ **Nota:** Este mÃ³dulo Ã© **OPCIONAL**. RAG (MÃ³dulo 03) resolve 90% dos problemas de forma mais simples e barata!

---

## ğŸ¯ Objetivos de Aprendizado

Ao completar este mÃ³dulo, vocÃª serÃ¡ capaz de:

- âœ… Decidir quando usar **Fine-Tuning vs RAG**
- âœ… Preparar datasets para fine-tuning
- âœ… Fazer fine-tuning via **OpenAI API**
- âœ… Usar **LoRA/PEFT** para fine-tuning eficiente
- âœ… Avaliar modelos fine-tuned
- âœ… Comparar custos e benefÃ­cios

---

## ğŸ“š ConteÃºdo

### ğŸ““ Notebooks

1. **01_preparacao_dados.ipynb** ğŸ“Š
   - Quando fazer fine-tuning?
   - Formato de dados (JSONL)
   - Qualidade vs quantidade
   - ValidaÃ§Ã£o de dataset
   - Exemplos prÃ¡ticos

2. **02_fine_tuning_gpt.ipynb** ğŸ”§
   - Fine-tuning via OpenAI API
   - Upload de dataset
   - Monitoramento do job
   - Testar modelo fine-tuned
   - Custos e pricing

3. **03_lora_peft.ipynb** ğŸ’¡ (AvanÃ§ado)
   - LoRA (Low-Rank Adaptation)
   - PEFT (Parameter-Efficient Fine-Tuning)
   - Fine-tuning local com menos recursos
   - ComparaÃ§Ã£o com full fine-tuning

4. **04_avaliacao_modelo.ipynb** ğŸ“ˆ
   - MÃ©tricas de avaliaÃ§Ã£o
   - Comparar: base model vs fine-tuned
   - Testes A/B
   - Quando vale a pena?

---

## ğŸ¤” Fine-Tuning vs RAG

### Quando usar Fine-Tuning?
âœ… **Use quando:**
- Tem milhares de exemplos de alta qualidade
- Precisa de consistÃªncia de estilo/tom
- DomÃ­nio muito especÃ­fico (mÃ©dico, jurÃ­dico)
- Quer reduzir latÃªncia (modelo menor)

âŒ **NÃƒO use quando:**
- Tem poucos exemplos (< 100)
- Dados mudam frequentemente
- RAG jÃ¡ resolve o problema
- OrÃ§amento limitado

### Quando usar RAG?
âœ… **Use quando:**
- Precisa de informaÃ§Ãµes atualizadas
- Quer transparÃªncia (cita fontes)
- NÃ£o tem muitos exemplos
- **â† 90% dos casos!**

---

## ğŸ”§ Tecnologias Utilizadas

### Fine-Tuning via API
- `openai` - Fine-tuning GPT-3.5
- `anthropic` - Fine-tuning Claude (beta)

### Fine-Tuning Local
- `transformers` - HuggingFace
- `peft` - Parameter-Efficient Fine-Tuning
- `bitsandbytes` - QuantizaÃ§Ã£o
- `accelerate` - Treinamento distribuÃ­do

### AvaliaÃ§Ã£o
- `datasets` - Carregar datasets
- `evaluate` - MÃ©tricas
- `wandb` - Tracking de experimentos

---

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Fine-Tuning via OpenAI API

```bash
# 1. Instalar dependÃªncias
pip install openai python-dotenv

# 2. Preparar dados
jupyter notebook 01_preparacao_dados.ipynb

# 3. Fazer fine-tuning
jupyter notebook 02_fine_tuning_gpt.ipynb
```

### OpÃ§Ã£o 2: Fine-Tuning Local (AvanÃ§ado)

```bash
# Requer GPU com 16GB+ VRAM
pip install transformers peft bitsandbytes accelerate

jupyter notebook 03_lora_peft.ipynb
```

---

## ğŸ’° Custos

### OpenAI Fine-Tuning

| Modelo | Training (por 1k tokens) | Usage (por 1k tokens) |
|--------|-------------------------|----------------------|
| GPT-3.5-turbo | $0.008 | $0.012 (8x base) |

**Exemplo real:**
```
Dataset: 1000 exemplos @ 500 tokens cada
Training: 1000 * 0.5 * $0.008 = $4
Uso (10k queries): 10 * 0.5 * $0.012 = $60/mÃªs

Total primeiro mÃªs: ~$64
```

### Local (LoRA/PEFT)
- **Custo:** $0 (usa sua GPU)
- **Hardware:** GPU 16GB+ VRAM
- **Tempo:** 2-8 horas

---

## ğŸ“Š PrÃ©-requisitos

### Para Fine-Tuning via API
- âœ… Dataset de qualidade (100+ exemplos)
- âœ… OpenAI API Key
- âœ… Budget (~$10-50 para testes)

### Para Fine-Tuning Local
- âœ… GPU NVIDIA (16GB+ VRAM)
- âœ… CUDA instalado
- âœ… ExperiÃªncia com PyTorch
- âš ï¸ PaciÃªncia (pode demorar horas!)

---

## ğŸ“ Conceitos-Chave

### ğŸ¯ Fine-Tuning
Treinar camadas finais de um modelo prÃ©-treinado com seus dados especÃ­ficos.

### ğŸ’¡ LoRA (Low-Rank Adaptation)
TÃ©cnica que treina apenas matrizes pequenas, economizando 90% de memÃ³ria.

### ğŸ“Š PEFT (Parameter-Efficient Fine-Tuning)
FamÃ­lia de tÃ©cnicas (LoRA, Prefix Tuning, etc) que tornam fine-tuning mais eficiente.

### ğŸ”¢ QuantizaÃ§Ã£o
Reduzir precisÃ£o (32-bit â†’ 8-bit â†’ 4-bit) para economizar memÃ³ria.

---

## ğŸ’¡ Exemplo de Caso de Uso

### Assistente de Atendimento ao Cliente

**Problema:** 
- Precisa seguir script especÃ­fico
- Tom formal e consistente
- Milhares de exemplos de conversas

**SoluÃ§Ã£o:**
```python
# 1. Coletar 1000+ conversas histÃ³ricas
# 2. Formatar em JSONL
# 3. Fine-tune GPT-3.5
# 4. Deploy do modelo customizado

# Resultado:
# - Respostas consistentes
# - Tom correto sempre
# - Menos tokens (modelo menor)
```

---

## ğŸ¯ Quando Fine-Tuning Vale a Pena?

### âœ… Casos Bons para Fine-Tuning

1. **ClassificaÃ§Ã£o com padrÃµes**
   - AnÃ¡lise de sentimento especÃ­fica
   - CategorizaÃ§Ã£o de tickets
   - DetecÃ§Ã£o de intenÃ§Ãµes

2. **GeraÃ§Ã£o com estilo especÃ­fico**
   - Comunicados formais
   - RelatÃ³rios tÃ©cnicos
   - Respostas padronizadas

3. **ExtraÃ§Ã£o estruturada**
   - JSON sempre no mesmo formato
   - Parsing de documentos especÃ­ficos

### âŒ Casos onde RAG Ã© Melhor

1. **Q&A sobre documentos**
   - Manuais tÃ©cnicos
   - Base de conhecimento
   - **â† Seu caso! Use RAG**

2. **InformaÃ§Ãµes atualizadas**
   - NotÃ­cias
   - PreÃ§os
   - Dados que mudam

3. **TransparÃªncia necessÃ¡ria**
   - Precisa citar fontes
   - Auditoria de respostas

---

## ğŸ“ˆ ComparaÃ§Ã£o PrÃ¡tica

```python
# CenÃ¡rio: Assistente de cÃ³digo Python

# OPÃ‡ÃƒO 1: RAG
â””â”€â”€ Custo: $0.01/query
â””â”€â”€ AtualizaÃ§Ã£o: InstantÃ¢nea (reindex)
â””â”€â”€ Qualidade: 8/10
â””â”€â”€ ImplementaÃ§Ã£o: 1 semana

# OPÃ‡ÃƒO 2: Fine-Tuning
â””â”€â”€ Custo: $50 treino + $0.12/query
â””â”€â”€ AtualizaÃ§Ã£o: Retreinar (horas/dias)
â””â”€â”€ Qualidade: 9/10
â””â”€â”€ ImplementaÃ§Ã£o: 3-4 semanas

# ESCOLHA: RAG! (90% dos casos)
```

---

## ğŸ”— PrÃ³ximos Passos

- ğŸ¤– **MÃ³dulo 05:** Agentes (podem usar modelos fine-tuned)
- ğŸ¯ **MÃ³dulo 06:** Projeto Final (RAG Ã© suficiente!)
- ğŸš€ **AvanÃ§ado:** Combinar RAG + Fine-Tuning

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o
- [OpenAI Fine-Tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)
- [HuggingFace PEFT](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)

### Tutoriais
- [Fine-Tuning GPT-3.5](https://platform.openai.com/docs/guides/fine-tuning)
- [LoRA Training Guide](https://huggingface.co/blog/lora)

### Papers
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)
- [QLoRA: Efficient Fine-Tuning](https://arxiv.org/abs/2305.14314)

---

## ğŸ“ˆ Status

â³ **PrÃ³ximo** (Opcional)

---

## ğŸ’¡ RecomendaÃ§Ã£o Final

**Para o seu projeto (Assistente TÃ©cnico):**
- âœ… Use **RAG** (MÃ³dulo 03)
- âŒ Pule Fine-Tuning (economize tempo e $$$)
- ğŸ¯ Foque no projeto final!

**Fine-tuning** Ã© interessante para aprender, mas nÃ£o Ã© necessÃ¡rio para seu objetivo.

---

## ğŸ‘¨â€ğŸ’» Autor

**Carlos H. B. Marques**
- GitHub: [@RickBamberg](https://github.com/RickBamberg)
- LinkedIn: [Carlos Henrique Bamberg Marques](https://www.linkedin.com/in/carlos-henrique-bamberg-marques/)

---

â¬…ï¸ [Voltar: RAG](../03_RAG/README.md) | â¡ï¸ [PrÃ³ximo: Agentes](../05_Agentes/README.md)
